---
title: "Análisis Discriminante"
author: "Pamela E. Pairo"
output:
  html_document:
    toc: yes
    code_folding: show
    toc_float: yes
    df_print: paged
    theme: united
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(tidyverse)
library(tidymodels)
library(factoextra)
library(mvShapiroTest)
library(biotools)
library(downloadthis)
library(MASS)
library(klaR)
```

```{r, echo = FALSE}

download_link(
  link = "https://github.com/PamelaPairo/maestria_DM/raw/main/AID/AD/analisis_discriminante.Rmd",
  button_label = "Download .Rmd",
  button_type = "danger",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)
```


Es una técnica de **clasificación** en donde hay más de una variable respuesta (cuantitativa) medida en grupos predeterminados.

El objetivo es:

- Separar los grupos, identificando las variables que permiten esa separación

- Clasificar a nuevos individuos

# Base de datos

Vamos a trabajar con la base de datos de `Iris`


```{r}
data(iris)
glimpse(iris)
```
Vamos a separar el dataset en train y test

```{r}
set.seed(123)#setear la semilla
# Create data split for train and test
df_split <- initial_split(iris,
                          prop = 0.9,
                          strata = Species)#en este caso no es necesario porque las clases están balanceadas

df_train <- df_split %>%
              training()

df_test <- df_split %>%
              testing()

# Número de datos en test y train
paste0("Total del dataset de entrenamiento: ", nrow(df_train))
paste0("Total del dataset de testeo: ", nrow(df_test))
```

```{r}
setosa<- subset(df_train[,1:4], df_train$Species == "setosa")
versicolor<- subset(df_train[,1:4], df_train$Species == "versicolor")
virginica <- subset(df_train[,1:4], df_train$Species=="virginica")
```

# Análisis Discriminante Lineal (LDA)

Este tipo de análisis es válido solo si se satisfacen los siguientes supuestos:

1- Distribución de normalidad multivariada

2- Independencia de las observaciones

3- Homocedasticidad.

## Verefiquemos supuestos

1- Normalidad multivariada

¿Cuál es la hipótesis estadística?

```{r}
mvShapiro.Test(as.matrix(setosa))
mvShapiro.Test(as.matrix(versicolor))  
mvShapiro.Test(as.matrix(virginica))
```
2- Independencia de las observaciones

Viene dada por el diseño

3- Homocedasticidad

Analizamos igualdad de matrices de varianzas y covarianzas:

```{r}
boxM(df_train[,-5],df_train[,5])
```
Entonces ¿qué concluimos?

Vamos a proseguir como si se hubiese cumplido todos los supuestos. Tener en cuenta que los resultados del LDA **no van a ser confiables en este caso**.

## LDA

```{r}
model_lda <- lda(Species~., data =df_train)
model_lda
```
**Coefficients of linear discriminants**: Muestra la combinación lineal de variables predictoras que se utilizan para formar la regla de decisión LDA.

Por ejemplo:

$\ LD1= 0.76*Sepal.Length+ 1.85*Sepal.Width - 2.25*Petal.Length -2.91*Petal.Width$

```{r}
lda.data <- cbind(df_train, predict(model_lda)$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = Species))
```

```{r}
predict(model_lda, df_test[,-5])
```

```{r}
predictions <- model_lda %>% predict(df_test)
names(predictions)

mean(predictions$class==df_test$Species)
```
Veamos la matriz de confusión en df_train

```{r}
table(predict(model_lda,type="class")$class,df_train$Species)
```
`partimat` muestra una matriz de gráficos para cada combinación de dos variables. Cada gráfico muestra una vista diferente de los mismos datos. Las regiones coloreadas delimitan cada área de clasificación. Se predice que cualquier observación que se encuentre dentro de una región pertenece a una clase específica. Cada gráfico también incluye la tasa de error aparente para esa vista de los datos.

```{r}
library(klaR) 
partimat (Species~. , data=df_train , method="lda")
```
Veamos la _performance_ en df_test

```{r}
lda.test <- predict(model_lda,df_test)
df_test$lda <- lda.test$class
table(df_test$lda,df_test$Species)
```
### Biplot

```{r}
#install.packages("devtools")
#library(devtools)
#install_github("fawda123/ggord")
library(ggord)
ggord(model_lda, df_train$Species, xlim = c(-10, 11))
```


## Análisis discriminante cuadrático (QDA)

El discriminante se dice cuadrático porque el término de segundo orden no se cancela como en el caso del discriminante lineal. QDA no asume la igualdad en la matriz de varianzas/covarianzas. En otras palabras, para QDA la matriz de covarianza puede ser diferente para cada clase.

Vamos a aplicar QDA, a pesar de que no se satisface el supuesto de normalidad multivariada.

```{r}
model_qda <- qda(Species ~ ., df_train)
model_qda
```

```{r}
partimat(Species ~ ., data=df_train, method="qda")
```

```{r}
table(predict(model_qda,type="class")$class,df_train$Species)
```

```{r}
lda.test_qda <- predict(model_qda,df_test)
df_test$qda <- lda.test_qda$class
table(df_test$qda,df_test$Species)
```
