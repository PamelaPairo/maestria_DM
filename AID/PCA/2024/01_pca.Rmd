---
title: "An치lisis de Componentes Principales"
author: "Pamela E. Pairo"
lang: es
format:
  html:
    theme:  flatly
    code-fold: show
    code-tools: true
    toc: true
    toc-location: left
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(tidyverse)
library(ggrepel)
library(gsheet)
library(rgl)
library(plot3D)
library(GGally)
library(reshape2)
library(plotly)
library(kableExtra)
```

**Contexto**

Una empresa de alimentos est치 planeando lanzar una campa침a de marketing el pr칩ximo mes con el objetivo de maximizar las ganancias. En una campa침a piloto con 2,240 clientes, aquellos que compraron la oferta fueron etiquetados como exitosos.


# An치lisis exploratorio 游늵

Carga de la base de datos

```{r}
df <-read.csv("ifood_df.csv")
glimpse(df)
```
**Descripci칩n de las columnas del dataset**

![](dictionary.png)

쮿ay valores faltantes?

```{r}
sum(is.na(df))# para saber cuantos na hay en la base de datos
```
쮿ay datos duplicados?

```{r}
any(duplicated(df))
```

```{r}
df_sample <- dplyr::distinct(df) |> #elimino datos repetidos
           sample_n(300)

df_num <- df_sample |> 
          select(1, 5:13, 25)#selecciono columnas de interes 

df_sample$marital_Single <- as.factor(df_sample$marital_Single)
df_sample$marital_Married <- as.factor(df_sample$marital_Married)
df_sample$Response <- as.factor(df_sample$Response)
```

```{r}
hist(df_sample$Age, 
     main = "Histograma de la edad",
     xlab = "Edad",
     ylab = "Frecuencia",
     col = "salmon",
     border = "black"
)
```

```{r}
recuentos <- table(df_sample$marital_Married)

# Calcular los porcentajes
porcentajes <- round(prop.table(recuentos) * 100)

# Crear las etiquetas con las categor칤as y los porcentajes
etiquetas <- paste(names(recuentos),"  \n", porcentajes, "%", sep = "")

# Crear el gr치fico de torta con las etiquetas de categor칤as y porcentajes
pie(recuentos, labels = etiquetas, main="Personas casadas (%)")
```

```{r}
# scatter plot

ggplot(df_sample, aes(x=MntWines, y=Income)) + 
  geom_point( colour='#56B4E9', shape=19)+
  xlab("Cantidad de vinos comprados")+
  ylab("Income")+
  theme_bw()
```

Trabajamos unicamente con las variables num칠ricas.

```{r}
data_long <- df_sample |> 
             select(1, 5:13,24, 25) |> 
             melt()
ggplot(data_long, aes(x=variable, y=value)) + 
    geom_boxplot() +
    facet_wrap(~variable, scale="free")
```

```{r}
ggplot(data_long, aes(x=variable, y=value, fill= Response)) + 
    geom_boxplot() +
    facet_wrap(~variable, scale="free")
```


**Representaci칩n tridimensional de variables**


```{r}
scatter3D(df_sample$MntWines, df_sample$NumWebPurchases, df_sample$Age, 
          phi = 0, 
          bty = "g",
          pch = 20, 
          cex = 2, 
          ticktype = "detailed", 
          colvar=NULL, 
          col = "blue",
          xlab="MntWines",
          ylab="NumWebPurchases",
          zlab="Age")
```

```{r}
mycolors <- c('royalblue1', 'red')
df_sample$color <- mycolors[ as.numeric(df_sample$Response) ]

plot3d(df_sample$MntWines, df_sample$NumWebPurchases, df_sample$Age, 
          type = 's', 
          radius = 10,
          col = df_sample$color,
          xlab="MntWines",
          ylab="NumWebPurchases",
          zlab="Age")

rglwidget()
```

**Correlograma**

```{r}
#Matriz de correlaci칩n
library(corrplot)

m_cor <- cor(df_num) 

# representa la matriz de correlaciones mediante c칤rculos
corrplot(m_cor,
         method="circle",
         type = "upper",
         diag= FALSE) 
```

# Matriz de Varianzas y covarianzas

```{r}
m_cov <-round(cov(df_num),2)

m_cov
```

Las varianzas tienen distintas unidades: No son comparables!!

Y la traza??

```{r}
traza_cov  <-sum(diag(m_cov))
traza_cov
```

La funci칩n `eigen()` calcula los autovectores y autovalores y los almacena en una lista bajo el nombre de _vectors_ y _values_, respectivamente.

```{r}
m_cov_AA <- eigen(m_cov)
autovalores_cov <- m_cov_AA$values #autovalores
round(autovalores_cov, 2)
```

Y si estandarizo los datos?

```{r}
datos_estandarizados <- data.frame(scale(df_num))

#calculo la matriz de covarianzas en los datos estandarizados
round(cov(datos_estandarizados),2)
```

# Matriz de Correlaciones

```{r}
m_cor <-round(cor(df_num),2)
m_cor |> knitr::kable(format = "html") |> 
  kable_styling() 
```

Y la traza?

```{r}
traza_cor  <-sum(diag(m_cor))
traza_cor
```

Traza = p (n칰mero de variables)

```{r}
desc_mat_cor <-eigen(m_cor)
autovalores_cor <-desc_mat_cor$values
round(autovalores_cor,2)
```

```{r}
print(sum(round(autovalores_cor,2)))
print(sum(round(autovalores_cov, 2)))
```

**Conclusi칩n**:la suma de los autovalores de cada matriz coincide con su respectiva traza

## 쯈ue matriz usar para extraer a los componentes?

**Matriz de varianzas y covarianzas**

-   Cuando las variables est치n en la misma escala

-   Da m치s peso a las variables con mayor varianza

-   En la interpretaci칩n interesa la diferencia entre varianzas

**Matriz de correlaci칩n**:

-   Cuando las variables est치n en distintas escalas o con valores muy distintos

-   Da el mismo peso a todas las variables

# PCA

**Objetivo del PCA**


Reducir el n칰mero de variables generando **nuevas variables que resuman la informaci칩n original**. Revelar patrones en los datos que pueden no ser detectados al analizar las variables por separado.

- Reducci칩n de dimensionalidad
- Detecci칩n de anomal칤as
- Decorrelaci칩n: Algunos algoritmos de aprendizaje autom치tico tienen dificultades con caracter칤sticas altamente correlacionadas. PCA transforma caracter칤sticas correlacionadas en componentes no correlacionados, lo que podr칤a ser m치s f치cil para que tu algoritmo trabaje con ellas

```{r}
#varianza de las variables
apply(X = df_num, 
      MARGIN = 2, 
      FUN = var)
```

Por defecto, `prcomp()` centra las variables para que tengan media cero, pero si se quiere adem치s que su desviaci칩n est치ndar sea de uno, hay que indicar *scale = TRUE*.

```{r}
pca <- prcomp(df_num,
              scale = TRUE)# con datos estandarizados
names(pca)
```

`center`:contienen la media de las variables previa estandarizaci칩n (en la escala original)

`scale`: contienen desviaci칩n t칤pica de las variables previa estandarizaci칩n (en la escala original)

`rotation`: contiene los *loadings*

## Cargas o _loadings_

```{r}

round(pca$rotation,2) |> knitr::kable(format = "html") |> 
  kable_styling() 
```

```{r}
contrib <- as.matrix(round(pca$rotation,2))
corrplot(contrib,is.corr=FALSE)
```

쮺u치l seria la combinaci칩n lineal de la primer componente?

$\ PC1= 0.38*Income+ 0.34*MntWines + 0.30*MntFruits +0.36*MntMeatProducts +0.33*MntFishProducts +0.31*MntSweetProducts +0.28*MntGoldProds- 0.03*NumDealsPurchases+ 0.26*NumWebPurchases+ 0.38*NumCatalogPurchases+ 0.11*Age$

Y de la segunda componente (PCA2)??

```{r echo=TRUE}
#loadings

carga1 = data.frame(cbind(X=1:length(df_num),
                          primeracarga=data.frame(pca$rotation)[,1]))
carga2 = data.frame(cbind(X=1:length(df_num),
                          segundacarga=data.frame(pca$rotation)[,2]))
cbind(carga1,carga2)
```

```{r echo=TRUE}
ggplot(carga1, aes(colnames(df_num) ,primeracarga)) + 
       geom_bar (stat="identity" , 
       position="dodge" ,
       fill ="royalblue" ,
       width =0.5 ) + xlab( 'Variables' ) + ylab('Primera carga' )+ theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Autovalores

쯈u칠 proporci칩n de la variabilidad total es explicada por las componentes?

```{r}
pca$sdev^2 # autovalores
```

```{r}
prop_varianza <- pca$sdev^2 / sum(pca$sdev^2)
prop_varianza
```

```{r}
ggplot(data = data.frame(prop_varianza, pc = 1:11),
       aes(x = pc, y = prop_varianza)) +
  geom_col(width = 0.4) +
  scale_y_continuous(limits = c(0,0.15)) +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. de varianza explicada")
```

```{r}
prop_varianza <- pca$sdev^2 / sum(pca$sdev^2)
prop_varianza_acum <- cumsum(prop_varianza)
prop_varianza_acum
```

```{r}
ggplot(data = data.frame(prop_varianza_acum, pc = 1:11),
       aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(x = "Componente principal",
       y = "Prop. varianza explicada acumulada")
```

## Biplot

- Los objetos son ordenados en funci칩n de su puntaje en cada uno de los componentes analizados

- Las variables son representadas como vectores

```{r}
biplot(x = pca, scale = 0, cex = 0.6, col = c("blue4", "brown3"))
```

Mejoremos la visualizaci칩n

```{r}
library(ggfortify)

df_sample$Response <- as.factor(df_sample$Response)

autoplot(pca, 
         data = df_sample, 
         colour = 'Response',
         loadings = TRUE, 
         loadings.colour = 'black',
         loadings.label = TRUE, 
         loadings.label.size = 5)
```


Vizualicemos las primeras 3 componentes:

```{r}
componentes <- pca[["x"]]
componentes <- data.frame(componentes)
componentes = cbind(componentes, df_sample$Response)

titulo = 'Primeras 3 CPs'

fig <- plot_ly(componentes, 
               x = ~PC1, 
               y = ~PC2, 
               z = ~PC3, 
               color = ~df_sample$Response,
               colors = c('#636EFA','#EF553B') ) |> 
   add_markers(size = 12)
 
fig <- fig |> 
  layout(
    title = titulo,
    scene = list(bgcolor = "#f3f2fc")
)

fig
```

쮺칩mo interpretamos el biplot?

쮺on cu치ntas componentes nos quedamos? Lo vemos la pr칩xima clase.

# Consideraciones importantes 游눠

九덢잺 No es una t칠cnica de inferencia estad칤stica

九덢잺 El PCA es mas eficiente si las variables se relacionan linealmente.

九덢잺 _Outliers_ pueden distorsionar el ordenamiento.

```{r}
sessionInfo()
```

