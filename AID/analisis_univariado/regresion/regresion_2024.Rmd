---
title: "Regresión Lineal y Múltiple"
author: "Pamela E. Pairo"
lang: es
format:
  html:
    theme:  flatly
    code-fold: show
    code-tools: true
    toc: true
    toc-location: left
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(tidyverse)
library("readxl")
library(MASS)
library(car)
```



```{r}
df <-read_csv("prueba.csv")


glimpse(df)
```
Se realiza un grafico de dispersión.

¿Hay valores faltantes?

```{r}
sum(is.na(df))# para saber cuantos na hay en la base de datos
```
¿Hay datos duplicados?

```{r}
any(duplicated(df))
```

```{r}
#df$work_years_in_company <- as.integer(df$work_years_in_company)
#df$salary_satisfaction <- as.integer(df$salary_satisfaction)
p<-ggplot(df, 
          aes(x =`Previous Scores` , y = `Performance Index`)) + 
          geom_point(aes(), colour ="deepskyblue", size=2)
p + xlab("Puntaje previo") +  ylab("Performance") 
```

## Regresión Lineal Simple

Se plantea el modelo de Regresión

```{r}
modelo1<-lm(`Performance Index` ~ `Previous Scores`, 
            data=df)
summary(modelo1)
```

Se calculan los residuos del modelo para chequear los supuestos.

```{r}
#Calculamos los residuos y los predichos
e<-resid(modelo1) # residuos
re<-rstandard(modelo1) #residuos estandarizados
pre<-predict(modelo1) #predichos
res<-cbind(df$`Previous Scores`,df$`Performance Index`,pre,e,round(re,2))
colnames(res)<-c("Puntaje anterior", "Performance", "Predichos", "Residuos", "residuos std") 
head(res)
```

Evaluamos el supuesto de normalidad de manera gráfica y mediante una prueba de hipótesis.

```{r}
#Supuestos
par(mfrow = c(1, 2))
plot(pre, re, xlab="Predichos", ylab="Residuos estandarizados",main="Grafico de dispersion de RE vs PRED" )
abline(0,0)
qqPlot(e)
```

```{r}
shapiro.test(e)
```
Como el p-valor= 0.284 es mayor a $\alpha$ =0.05, se asume normalidad en los datos.

**Intervalo de Confianza**

Se calcula el intervalo de confianza del 95% para la ordenada al origen y la pendiente del modelo de regresión. 

Para cambiar el nivel de confianza cambiar el parámetro `level`

```{r}
confint(modelo1)#por default es del 95%
```
Se agrega la recta al gráfico y la banda de confianza.

```{r}

p + geom_smooth(method = "lm", 
                se = TRUE)#para mostrar la banda de confianza
```

Entonces, se analiza el el modelo propuesto y como el p-valor dado que es menor al valor de significancia, entonces la pendiente es significativamente distinta a cero y por ende el modelo lineal propuesto es válido.

```{r}
summary(modelo1)
```

Por el valor obtenido de $\ R^2= 0.84$ se deduce que el modelo propuesto explica el 86,63% de la variabilidad de los datos.

```{r}
#coeficiente de determinación (en summary)
summary(modelo1)$r.squared
```

## Regresión Lineal Múltiple

Se incluye la variable `antiguedad` al modelo.

$\LARGE Performance_{i}= \beta_{0} + \beta_{1} PuntajePrevio + \beta_{2} HorasEstudiadas + \varepsilon_i$

```{r}
modelo2<-lm(`Performance Index` ~ `Previous Scores`+ `Hours Studied`, 
            data=df)
```

**Gráficos de dispersión**

```{r}
library(GGally)
ggpairs(df, diag = list(continuous = "blankDiag"))
```
Supuestos

```{r}
#Calculamos los residuos y los predichos
e_m2<-resid(modelo2) # residuos
re_m2<-rstandard(modelo2) #residuos estandarizados
pre_m2<-predict(modelo2) #predichos
res_m2<-cbind(df$`Previous Scores`,df$`Performance Index`,pre_m2,e_m2,round(re_m2,2))
colnames(res_m2)<-c("superficie", "precio", "Predichos", "Residuos", "residuos std") 
head(res_m2)
```

```{r}
par(mfrow = c(1, 2))
plot(pre_m2, re_m2, xlab="Predichos", ylab="Residuos estandarizados",main="Grafico de dispersion de RE vs PRED" )
abline(0,0)
qqPlot(e_m2)
```
Se chequea normalidad

```{r}
shapiro.test(resid(modelo2))
```
Vemos los resultados del modelo

```{r}
summary(modelo2)
```
De acuerdo a los resultados obtenidos, el modelo propuesto es significativo y válido (p-valor < $\alpha=0.05$), resultando significativo únicamente el coeficiente para la variable `surface_total`(p<0.05). El 87% de la variabilidad de los datos es explicado por el modelo de regresión múltiple.

## Bonus track: Residuos parciales

Los gráficos de dispersión de Y vs cada X muestran el efecto sobre la variable respuesta (VR) de una variable explicatoria (VE) sin considerar el efecto de las otras VE. Los gráficos de residuos parciales muestran el efecto parcial sobre la VR de una VE cuando las otras VE son incluidas en el modelo y mantenidas constantes.

```{r}
library(faraway)
prplot(modelo2,1)
```
```{r}
library(plotly)

grid_x1 <- seq(min(df$`Hours Studied`), max(df$`Hours Studied`))
grid_x2 <- seq(min(df$`Previous Scores`), max(df$`Previous Scores`))
grid <- expand.grid(`Hours Studied` = grid_x1, `Previous Scores` = grid_x2)
grid$y_pred <- predict(modelo2, newdata = grid)


plot_ly(df, x = ~`Hours Studied`, y = ~`Previous Scores`, z = ~`Performance Index`, type = "scatter3d", mode = "markers", name = "Datos") %>%
  add_trace(x = grid$`Hours Studied`, y = grid$`Previous Scores`, z = grid$y_pred, type = "mesh3d", opacity = 0.5, name = "Superficie de Regresión") %>%
  layout(scene = list(xaxis = list(title = 'Horas de estudio'),
                      yaxis = list(title = 'Puntaje previo'),
                      zaxis = list(title = 'Performance')),
         title = "Regresión Múltiple")
```






