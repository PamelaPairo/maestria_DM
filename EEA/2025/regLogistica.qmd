---
title: "Regresión Logística"
author: "Pamela Eugenia Pairo"
lang: es
format:
  html:
    theme: flatly
    code-fold: show
    code-tools: true
    toc: true
    toc-location: left
---

```{r, echo=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# Cargamos las librerías que vamos a utilizar
library(tidyverse)
library(tidymodels)
library(modelr)
library(GGally)
library(pROC)
library(cowplot)
library(OneR)
library(rlang)
library(caret)
```

# Presentación del caso de estudio

Vamos a trabajar con una base de datos extraída de [Kaggle](https://www.kaggle.com/code/robinreni/cardiovascular-disease-eda-detailed/notebook). Es una base de datos que consiste de 69301 registros de pacientes a los que se les registró 12 caracteristicas asociadas a una enfermedad cardiovascular.

El objetivo de esta clase es utilizar diferentes modelos de regresión logística para predecir la presencia o ausencia de enfermedad cardiovascular (ECV) utilizando los resultados del examen del paciente.

**Descripción de los datos**

- Age: edad del paciente (días)
- Height: altura del paciente (cm)
- Weight: peso del paciente (kg)
- Gender: sexo biológio del paciente (1: mujer, 2:varón)
- Systolic blood pressure: Presión arterial sistólica
- Diastolic blood pressure: Presión arterial diastólica
- Cholesterol: colesterol en sangre del paciente (1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal)
- Glucose: glucosa (1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal)
- Smoking: fuma/no fuma
- Alcohol intake: consume alcohol/ no consume alcohol
- Physical activity; realiza actividad física/ no realiza actividad física
- Cardiovascular disease: variable target (0:no, 1:si)

```{r}
df <- read.csv("cardio_train.csv", sep = ";")

colSums(is.na(df))# chequeamos si hay datos faltantes
```

```{r}
glimpse(df)
```

Se genera una muestra de tamaño 1000 con la que se realizaran los análisis y se analiza si hay desbalance en la variable respuesta.

```{r}

df <- df %>% 
        sample_n(1000)

df %>%
  group_by(cardio) %>%
  summarise(cnt = n()) %>%
  mutate(freq = round(cnt / sum(cnt), 2))
```
## Partición de la base de datos

```{r}
set.seed(2025)

df_split <- initial_split(df,
                          prop = 0.8)

train<- df_split %>%
              training()

test <- df_split %>%
              testing()

# Número de datos en train
paste0("Total del dataset de entrenamiento: ", nrow(train))
```
Analizamos como quedo el balance de clases para `cardio` en cada dataset.

```{r}
# calculamos la distribución de clase en cada dataset
train_ <- train %>% 
  group_by(cardio) %>% 
  summarise(numero_casos=n()) %>%
  mutate(prop = round(prop.table(numero_casos)*100,2))
test_ <- test %>% 
  group_by(cardio) %>% 
  summarise(numero_casos=n()) %>%
  mutate(prop = round(prop.table(numero_casos)*100,2))
# armamos tabla conjunta para graficar
distrib = cbind(rbind(train_, test_), dataset = c("train", "train", "test", "test"))

# graficamos las distribuciones
ggplot(distrib, aes(x = cardio, y = prop, fill = factor(cardio), label = prop)) + 
         geom_bar(stat="identity", position = "dodge") + facet_wrap(~ dataset) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "", y = "Proporción en %", title = "Proporción de cardio por dataset") + 
  guides(fill=guide_legend(title="cardio"))+
  theme_bw() +
  scale_fill_brewer(palette="Set2")
```

```{r}
glimpse(train)
```
Seleccioamoslas variables con las que vamos a trabajar y les asignamos el tipo de dato correspondiente.

```{r}
cols <- c("age", 
          "height", 
          "weight", 
          "gender", 
          "cholesterol",
          "gluc",
          "cardio")

train$gender <- as.factor(train$gender)
train$cholesterol <- as.factor(train$cholesterol)
train$gluc <- as.factor(train$gluc)

test$gender <- as.factor(test$gender)
test$cholesterol <- as.factor(test$cholesterol)
test$gluc <- as.factor(test$gluc)

```

```{r}

# graficamos con ggpairs coloreando por variable a predecir

g <- train %>% 
        mutate(cardio = factor(cardio)) %>%
        select(all_of(cols)) %>% 
        ggpairs(title = "Correlograma de variables",
                mapping = aes(colour= cardio),
                progress = FALSE, 
                lower=list(combo=wrap("facethist", binwidth=0.8))) +
        theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
        theme_bw() +
        scale_fill_brewer(palette="Set2") +
        scale_color_brewer(palette="Set2")
g
```

### Regresión lineal

En este caso estamos modelando la probabilidad de la siguiente manera: 

$P(X)= \beta_0 + \sum\limits_{j=1}^p \beta_j X_j$

Veamos que tan bueno es el modelo lineal para esto, usando la edad como predictor.

```{r}
mrl <- train %>% 
              lm(formula = cardio ~ weight) 
tdy = mrl %>% tidy() 
tdy
mrl %>% glance()
```

Los estimadores son significativos y el test de significatividad global del modelo también es significativo.

Veamos un gráfico de nuestro modelo.

```{r, echo=FALSE}
ggplot(train, aes(weight, cardio)) + 
  geom_point(aes(color=factor(cardio))) +
  scale_color_brewer(palette = "Set2") + 
  geom_abline(intercept = tdy$estimate[1], slope = tdy$estimate[2], color='forestgreen', size=2) + 
  labs(title="Modelo Lineal Simple", color='Clase') +
  lims(y=c(-1,2))+
  theme_bw()
```

Parece tener bastantes problemas para estimar la probabilidad de supervivencia de los individuo: no existe un punto de corte claro, la predicción podría ser mayor a 1 o menor a cero llegado el caso.

## Recap de Regresión Logística

### **Odds**

Cociente entre la probabilidad de éxito de un evento y la probabilidad de que no ocurra.

$Odds = \frac{P(x)}{1-P(x)}$

Ej. si _Odds_ es 3 indica que por cada 4 repeticiones del evento se espera que ocurran 3 y que una no ocurra.

Odds < 1 : es mas probable que no ocurra a que si

Odds = 1 : equiprobabilidad

Odds > 1: es mas probable que el evento ocurra a que no.

En nuestro caso:

$Odds = \frac{391/800}{409/800}= 0.9558 \approx \frac{191}{200}$

Por cada 191 pacientes con ECV, 200 no la tienen.

### **Logit**

$Logit = \log {\frac{P(x)}{1-P(x)}}= \log Odds$

### **_Odds Ratio_ (OR)**

Es una medida de magnitud de efecto. Si tenemos el siguiente modelo de regresión logística


$\log\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1 X$

El odds ratio asociado a la variable $\ X $ es:

$\text{OR} = e^{\beta_1}$

OR = 1 No hay efecto

OR > 1 asociación positiva

OR <1 asociación negativa

### Escalas de análisis

1- Predictor lineal

2- Odds

3- Variable respuesta

![Imagen adaptada de la clase de RL de Adriana Perez](rl.png){}

## Ahora si modelamos los datos con una Regresión Logística

Para evitar estos problemas, usamos la **función logística**.

$P(Y=1|X)= \frac{e^{\beta_0 + \sum\limits_{j=1}^p \beta_j X_j}}{1+e^{\beta_0 + \sum\limits_{j=1}^p \beta_j X_j}}$

Esta función acota el resultado entre 0 y 1, lo cual es mucho más adecuado para modelar una probabilidad.

Luego de hacer algunas operaciones, podemos llegar a la expresión:

$\log {\frac{P(x)}{1-P(x)}}= \beta_0 + \sum\limits_{j=1}^p \beta_j X_j$

## Regresión Logística

La funcíón `glm()` nos permite crear un modelo lineal generalizado (Generalized Linear Model). Al igual que la función `lm()` toma como argumentos una **formula** y los **datos** pero también se debe especificar el argumento **family**: indicamos la distribución del error y la función link que vamos a utilizar en el modelo. 

Algunas familias son:

* *Binomial*: link=logit

* *Poisson*: link=log

* *Gaussiana*: link=identidad

Como estamos trabajando con un fenómeno que suponemos tiene una distribución binomial, así lo especificamos en el parámetro **family**.

Realizamos un modelo de regresión logística para predecir la si el paciente tiene una ECV en función de **weight**, **age** y **gender**. 

$\log {\frac{P(x)}{1-P(x)}}= \beta_0 + \beta_1 weight + \beta_2 age + \beta_2 varón$

```{r}
# modelo de regresión logística 
glm1 <- glm(data = train,
            cardio ~ weight + gender, 
            family = 'binomial')

# veo los resultados
tidy(glm1)
glance(glm1)
```

### Interpretación de los coeficientes del modelo

Modelo obtenido

$\log {\frac{P(x)}{1-P(x)}}= -1.69 + 0.02* weight + 0.07*varón$

**Peso**

Se espera un aumento de 0.022 unidades en el log de odds por cada aumento de 1kgr en el peso (manteniendo el resto de las variables constantes). La probabilidad de contraer una ECV aumenta con el aumento de peso del paciente.

$\ OR = e^{\beta_{weight}}= e^{0.022}= 1.022$

Por cada aumento de 1 kgr se estima que el odds de contraer una ECV aumente 2.22%

**Género**

$\ Odds_{varón} = {\frac{Prob_{ECV} /varón}{Prob_{noECV}/varón}}$

$\ Odds_{mujer} = {\frac{Prob_{ECV} /mujer}{Prob_{noECV}/mujer}}$

$\ OR = {\frac{Odds_{varón}}{Odds_{mujer}}}= e^{\beta_{género}}= e^{0.07}$

Es decir, si un paciente pertenece a la categoría varón tiene mas probabilidad de contraer una ECV que si pertenece a la categoría mujer. Ser varón es factor de riesgo. 

### Devianza

$\ Devianza Explicada = {\frac{Dev_{mod null} - Dev_{Mod}}{Dev_{mod null}}}$

$\ Devianza Explicada = {\frac{1108.63 - 1083.82}{1108.63}}= 0.02$


## Selección de modelos

Se generan la combinación de todos los modelos posibles.

```{r}
vars <- c("gender", "weight", "cholesterol")

# Crear todas las combinaciones posibles de predictores
combs <- unlist(
  lapply(1:length(vars), function(i) combn(vars, i, simplify = FALSE)),
  recursive = FALSE
)

# Crear una lista de fórmulas
formulas <- map(combs, ~ reformulate(termlabels = .x, response = "cardio"))

formulas

```

```{r}
modelos <- map(formulas, ~ glm(.x, data = train, family = binomial))

```

```{r}
resultados <- tibble(
  formula = map_chr(formulas, format),
  deviance = map_dbl(modelos, ~ .$deviance),
  null_deviance = map_dbl(modelos, ~ .$null.deviance),
  AIC = map_dbl(modelos, AIC)
) %>%
  mutate(dev_explicada = 1 - deviance / null_deviance)%>%
  arrange(desc(dev_explicada))

resultados

```


```{r}
# Añadir las predicciones

prediction_full <- map2(modelos, formulas, ~ {
  tibble(
    .fitted = predict(.x, newdata = test, type = "response"),
    cardio = test$cardio
  )
})

```

```{r}
roc_df <- map2_dfr(modelos, resultados$formula, ~ {
  roc_obj <- roc(train$cardio, predict(.x, type = "response"))
  tibble(
    tpr = roc_obj$sensitivities,
    fpr = 1 - roc_obj$specificities,
    formula = .y
  )
})

ggplot(roc_df, aes(x = fpr, y = tpr, color = formula)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed") +
  labs(x = "1 - Especificidad", y = "Sensibilidad", title = "Curvas ROC de todos los modelos") +
  theme_minimal()
```
```{r}
auc_values <- map_dbl(modelos, ~ auc(roc(train$cardio, predict(.x, type = "response"))))

resultados <- resultados %>%
  mutate(AUC = auc_values)

resultados

```

```{r}
# Supongamos que 'mejor_modelo'

best_model <- glm(data = train,
            cardio ~ weight + gender+ active, 
            family = 'binomial')

test_model <- tibble(
  .fitted = predict(best_model, newdata = test, type = "response"),
  cardio = test$cardio
)

prediction_metrics <- function(cutoff, predictions) {
  tab <- predictions %>% 
    mutate(predicted_class = factor(if_else(.fitted > cutoff, 1, 0), levels = c(0,1)),
           cardio = factor(cardio, levels = c(0,1)))
  
  cm <- confusionMatrix(tab$predicted_class, tab$cardio, positive = "1")
  
  tidy(cm) %>%
    select(term, estimate) %>%
    filter(term %in% c('accuracy','sensitivity','specificity','precision')) %>%
    mutate(cutoff = cutoff)
}

```


```{r}
cutoffs <- seq(0.05, 0.95, 0.05)
metricas_df <- map_df(cutoffs, ~ prediction_metrics(.x, predictions = test_model)) %>%
  mutate(term = as.factor(term), estimate = round(estimate, 3))

```



```{r}
ggplot(metricas_df, aes(x = cutoff, y = estimate, color = term, group = term)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  theme_bw() +
  labs(
    title = "Accuracy, Sensitivity, Specificity y Precision vs Cutoff",
    x = "Punto de corte",
    y = "Valor de la métrica",
    color = "Métrica"
  )

```

```{r}
sel_cutoff = 0.48

# calculamos las predicciones sobre el dataset de train
table_train = augment(x = best_model, type.predict='response')
# Clasificamos utilizamos el punto de corte
table_train = table_train %>% 
  mutate(predicted_class = if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(), 
         cardio = factor(cardio))
# Creamos la matriz de confusión
confusionMatrix(table(table_train$predicted_class, table_train$cardio), positive = "1")
```
```{r}
# Agregamos la predicciones al dataset de testeo
table_test = augment(x = best_model, newdata=test, type.predict='response') 
# Clasificamos utilizamos el punto de corte
table_test = table_test %>% 
  mutate(predicted_class = if_else(.fitted>sel_cutoff, 1, 0))
# Creamos la matriz de confusión
confusionMatrix(table(table_test$predicted_class, table_test$cardio), positive = "1")
```

